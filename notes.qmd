
# Notes for Habitat Suitability assignment

## Fuzzy Logic Model

You can find it hereLinks to an external site., or under the "Modules" section on Canvas. Elsa has also provided a link to a conversation with ChatGPTLinks to an external site. that she had on how to implement fuzzy models using scikit-fuzzy in Python, as another resource for you. 

- [Elsa Zoom on Fuzzy](https://cuboulder.zoom.us/rec/play/EnTi2FyvDddFKN86INR7iypERZ59IHE5xxZXSS3R9vQAjJ4RczjpwYqFa63JhF9Hdq1Dv9U1iVZX65Vw.qfKwpud-sV9GAqKp)
- [Elsa ChatGPT](https://chatgpt.com/share/67c094af-9724-8000-9004-6f25d266cd85)
- [Fall 2024 habitatSuitability/4_build](https://github.com/byandell-envsys/habitatSuitability/blob/main/4_build.ipynb)
- [SciKit Fuzzy](https://pypi.org/project/scikit-fuzzy/)

A fuzzy logic model is one that is built on expert knowledge rather than
training data. You may wish to use the
[`scikit-fuzzy`](https://pythonhosted.org/scikit-fuzzy/)
library, which includes many utilities for building this sort of model.
In particular, it contains a number of **membership functions** that
can convert your data into values from 0 to 1 using information such as,
for example, the maximum, minimum, and optimal values for soil pH.

To train a fuzzy logic habitat suitability model:

1. Research S. nutans, and find out what optimal values are for each variable
you are using (e.g. soil pH, slope, and current climatological annual precipitation). 
1. For each **digital number** in each raster, assign a **continuous** value
from 0 to 1 for how close that grid square is to the optimum range
(1=optimal, 0=incompatible). 
1. Combine your layers by multiplying them together.
This will give you a single suitability number for each square.
1. Optionally, you may apply a suitability threshold to make
the most suitable areas pop on your map.

> **Tip**
>
> If you use mathematical operators on a raster in Python, it will
> automatically perform the operation for every number in the raster.
> This type of operation is known as a **vectorized** function. **DO NOT
> DO THIS WITH A LOOP!**. A vectorized function that operates on the
> whole array at once will be much easier and faster.

-   use hill functions to transform harmonized DataArrays into 0-1 DataArrays
-   multiply them together
  
Resources:

- [USDA Natural Resources Convervations Service: Plant Guide: Indiangrass]


```{python}
#conda install skfuzzy
```

Libraries

```{python}
#pip install ~/Documents/GitHub/landmapy
```

Libraries

```{python}
from math import floor, ceil
import cartopy.crs as ccrs
import geopandas as gpd
import hvplot.pandas
import hvplot.xarray
import numpy as np
import rioxarray as rxr
import rioxarray.merge as rxrmerge
import skfuzzy
import xarray as xr
```

My version:

```python
from landmapy.initial import create_data_dir # create (or retrieve) data directory
from landmapy.plot import plot_gdf_state # plot gdf with state overlay

%store -r buffalo_gdf
try:
    buffalo_gdf
except NameError:
    data_dir = create_data_dir('habitat')
    # Read all grasslands GeoJSON into `grassland_gdf`.
    grassland_url = f"{data_dir}/National_Grassland_Units_(Feature_Layer).geojson"
    grassland_gdf = gpd.read_file(grassland_url)
    # Subset to desired locations.
    buffalo_gdf = grassland_gdf.loc[grassland_gdf['GRASSLANDNAME'].isin(
        ["Buffalo Gap National Grassland", "Oglala National Grassland"])]
    %store buffalo_gdf
    print("buffalo_gdf created and stored")
else:
    print("buffalo_gdf retrieved from StoreMagic")

```

Elsa's version

```{python}
grassland_url = (
    "https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.NationalGrassland.zip")
grassland_gdf = gpd.read_file(grassland_url)
grassland_gdf.info
```

```{python}
oglala_gdf = grassland_gdf[grassland_gdf.GRASSLANDN.str.contains('Oglala')]
(
    oglala_gdf
    .to_crs(ccrs.Mercator())
    .hvplot(tiles='EsriNatGeo', line_width=3, fill_color=None)
)
```

```{python}
oglala_gdf
```

```{python}
years = (2010, 2031)
year_min = floor((min(years) - 1) // 5) * 5 + 1
year_max = ceil((max(years) - 1) // 5) * 5 + 5
print(year_min, year_max)

```

```{python}
from landmapy.polaris import merge_soil

ph_da = merge_soil(oglala_gdf, "ph", "mean", "60_100", 0.1)
ph_da.plot()
```

```{python}
from landmapy.thredds import process_maca_list

maca_da_list = process_maca_list({'oglala': oglala_gdf}, years = (2011, 2040))
```

**Stuck on next line**

```{python}
maca_da = xr.concat(maca_da_list, dim='year')
```

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[9], line 1
----> 1 maca_da = xr.concat(maca_da_list, dim='year')

File ~/miniconda3/envs/earth-analytics-python/lib/python3.11/site-packages/xarray/core/concat.py:290, in concat(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs, create_index_for_new_dim)
    277     return _dataset_concat(
    278         objs,
    279         dim=dim,
   (...)
    287         create_index_for_new_dim=create_index_for_new_dim,
    288     )
    289 else:
--> 290     raise TypeError(
    291         "can only concatenate xarray Dataset and DataArray "
    292         f"objects, got {type(first_obj)}"
    293     )

TypeError: can only concatenate xarray Dataset and DataArray objects, got <class 'dict'>
```

```{python}
maca_min_da = (
    maca_da
    .resample({'time': 'Y'})
    .sum()
    .min('time')
    .rio.write_crs(4236) 
    .rio.reproject_match(ph_da)
)
maca_min_da.plot()
```

```{python}
```


## GBIF review

- https://canvas.colorado.edu/courses/115453/modules/items/6278820
  - code: .gA?103.
- https://cuboulder.zoom.us/rec/play/QFgqRKpVUAwDu4aJazn78I3FdNyVRXUXLdQILQCcB4o6DC9lRK45hVkM2Pb8NSsjiK8J1QrbsboIyXdk.wjmuYuUC8T1EG8T1?accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&startTime=1740463281000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fcuboulder.zoom.us%2Frec%2Fshare%2FGtk19F9JjJayCXTHDnSPoQqrck0arcH32N8BurvZK3opQSCwhUVYDOYyECI0QoGA.ASZTR9CgYjN-DCsi%3FstartTime%3D1740463281000
- https://pygbif.readthedocs.io/en/latest/
- https://github.com/earthlab-education/species-distribution-coding-challenge-byandell/blob/main/notebooks/siberian-crane-species-download.ipynb 
- earthlab-education and look at repos
- [Fall 2024 Species](https://github.com/earthlab-education/species-distribution-coding-challenge-byandell)
  - [gbif.py](https://github.com/earthlab-education/species-distribution-coding-challenge-byandell/blob/main/gbif.py)
  - [sandhill_crane.qmd](https://github.com/earthlab-education/species-distribution-coding-challenge-byandell/blob/main/sandhill_crane.qmd)
  - [siberian_crane.qmd](https://github.com/earthlab-education/species-distribution-coding-challenge-byandell/blob/main/siberian_crane.qmd)

```{python}
#pip install pygbif
```

```{python}
## reproducible file paths
import os
from glob import glob
import pathlib

## GBIF packages
import pygbif.occurrences as occ
import pygbif.species as species
from getpass import getpass

## unzip and handle gbif data
import zipfile
import time

## spatial data
import geopandas as gpd
import xrspatial as xr

## other data
import numpy as np
import pandas as pd
import rioxarray as rxr
import rioxarray.merge as rxrm

## invalid geometries
from shapely.geometry import MultiPolygon, Polygon

## viz data
import holoviews as hv
import hvplot.pandas
import hvplot.xarray
```

```{python}
# make repro file paths
data_dir = os.path.join(
    # home directory
	pathlib.Path.home(),
	
	### eda directory
	'earth-analytics',
    'data',
    'hab_suit'
)
os.makedirs(data_dir, exist_ok = True)
```

Sutdy species: Lupinus argenteus (silvery lupine)

```{python}
gbif_dir = os.path.join(data_dir, 'gbif_lupine')
```

```{python}
reset_credentials = False

credentials = dict(
    GBIF_USER=(input, 'GBIF username:'),
    GBIF_PWD=(getpass, 'GBIF password:'),
    GBIF_EMAIL=(input, 'GBIF email:')
)
for env_variable, (prompt_func, prompt_text) in credentials.items():
    if reset_credentials and (env_variable in os.environ):
        os.environ.pop(env_variable)
    if not env_variable in os.environ:
        os.environ[env_variable] = prompt_func(prompt_text)
```

Now in GBIF. Supply species code.

```{python}
species_name = 'Lupinus argenteus'
species_info = species.name_lookup(species_name, rank='SPECIES')
# grab first
first_result = species_info['results'][0]
species_key = first_result['nubKey']
first_result['species'], species_key
```

```{python}
## assign species code
species_key = 2964374
```

Do this once.
Had trouble withing loop below so tried outside.

```python
gbif_query = occ.download([
        f"speciesKey = {species_key}",
        "hasCoordinate = True"
    ])
gbif_query
```

```{python}
gbif_pattern = os.path.join(gbif_dir, '*.csv')
## download once
if not glob(gbif_pattern):
    #***with error status code 503check your number of active downloads***
    gbif_query = occ.download([
        f"speciesKey = {species_key}",
        "hasCoordinate = True"
    ])

    if not 'GBIF_DOWNLOAD_KEY' in os.environ:
        os.environ['GBIF_DOWNLOAD_KEY'] = gbif_query[0]
        download_key = os.environ['GBIF_DOWNLOAD_KEY']
        # wait for download to build
        wait = occ.download_meta(download_key)
        while not wait == 'SUCCEEDED':
            wait = occ.download_meta(download_key)['status']
            time.sleep(5)

    # download data
    # ***'function' object has no attribute 'get'***
    download_info = occ.download_get(
        os.environ['GBIF_DOWNLOAD_KEY'],
        path = data_dir
    )
    # unzip
    with zipfile.ZipFile(download_info['path']) as download_zip:
        download_zip.extractall(path = gbif_dir)

## find csv file path
gbif_path = glob(gbif_pattern)[0]
```

## Class

See
[EDA Reference for Python Coding: Classes](https://github.com/byandell-envsys/EarthDataAnalytics/blob/main/references.md#classes)
for references and discussion of classes.

A 
[class](https://docs.python.org/3/tutorial/classes.html)
is a function with output of an object that has new methods, which are in turn functions
defined in the class.
In addition, the `@property` decorator defines attributes for the object.
The main use of classes are to:

- add functionality to class
- streamline different functions with same parameters to keep track of metadata

### Examples

Simple example with representer `__repr__`.

```{python}
import pandas as pd
import xarray as xr

class ArrayDataFrame(pd.DataFrame): # inherits pd.DataFrame class

    def set_array_column(self, arrays):
        self['arrays'] = arrays
        return self

    def __repr__(self):
        for_printing = self.copy()
        for_printing.arrays = [arr.min() for arr in self.arrays]
        return for_printing.__repr__()
```       

```{python}
ArrayDataFrame({'url': ['https://...']}).set_array_column([xr.DataArray()])
```

Show example where class would help.

```{python}
import random
import numpy as np
import xarray as xr

def gen_data_array(size=10):
    data = (
        np.array([random.gauss(0,1) for _ in range(size**2)]).reshape(size, size))
    data = xr.DataArray(
        data = data,
        coords = {
            'x': [i * random.uniform(0,1) for i in range(size)],
            'y': [i * random.uniform(0,1) for i in range(size)]
        },
        dims=['x','y']
    )
    return data
```

```{python}
gen_data_array(10)
```

```{python}
df_len = 10
my_df = pd.DataFrame({
    'id': list(range(df_len)),
    'array': [gen_data_array(10) for _ in range(df_len)]
})
print(my_df)
```

```{python}
class FunDataFrame(pd.DataFrame):
    # represent
    def __repr__(self):
        return 'stuff!'
```

```{python}
my_df
```

Add ipython method (under the hood concept)

```{python}
class FunDataFrame(pd.DataFrame):
    # represent
    def __repr__(self):
        return 'stuff!'
    # ipython method
    def _repr_html_(self):
        return 'more stuff!!!'
```

```{python}
my_df
```


```{python}
class FunDataFrame(pd.DataFrame):

    # attribute to make a dataframe
    @property
    def _df_for_repr_(self):
        df = self.drop(columns = ['array']).copy()
        return df
    # represent
    def __repr__(self):
        return self._df_for_repr_.__repr__()
    # ipython method
    def _repr_html_(self):
        return self._df_for_repr_._repr_html_()
```

```{python}
my_df
```

Set up my dataframe class to show what I want

```{python}
class FunDataFrame(pd.DataFrame):

    # define array_types (does not appear to be used yet) 
    array_types = [xr.DataArray]

    # attribute to return `array_cols`
    @property
    def array_cols(self):
        array_cols = []
        for col in self:
            if type(self[col][0]) == xr.DataArray:
                array_cols.append(col)
                return array_cols

    # more complicated attribute
    @property
    def _df_for_repr_(self):
        df = self.drop(columns = self.array_cols).copy()
        for array_col in self.array_cols:
            arr_str_list = []
            for arr in self[array_col]:
                arr_min = round(float(arr.x.min()), 2)
                arr_max = round(float(arr.x.max()), 2)
                arr_str_list.append(
                    f'DataArray(x ({arr_min}, {arr_max}))'
                )
            df[array_col] = arr_str_list
            #df[array_col] = ['DataArray' for _ in range(len(df))]
        return df
    
    # represent
    def __repr__(self):
        return self._df_for_repr_.__repr__()
    # ipython method
    def _repr_html_(self):
        return self._df_for_repr_._repr_html_()
```

```{python}
my_df = FunDataFrame({
    'id': list(range(df_len)),
    'array': [gen_data_array(10) for _ in range(df_len)],
    'array2': [gen_data_array(10) for _ in range(df_len)]})
my_df
```

